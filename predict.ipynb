{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d884db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.all import *\n",
    "from fastai.vision.all import *\n",
    "from IPython.utils import io\n",
    "import librosa\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d3c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path(\"./Dataset/Dataset/IRMAS_Training_Data\")\n",
    "noise_path = Path(\"./Dataset/Dataset/IRMAS_Training_Data/noi\")\n",
    "valid_path = Path(\"./Dataset/Dataset/IRMAS_Validation_Data\")\n",
    "test_path = Path(\"./Dataset/Dataset/IRMAS_Test_Data\")\n",
    "grand_path = Path(\"./Dataset/Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b40f9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_song_files = FileGetter(extensions='.wav', recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad8d09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_IRMAS_train(pat: Path):\n",
    "    return str(pat).find(\"IRMAS_Training_Data\") != -1\n",
    "\n",
    "def is_IRMAS_valid(pat: Path):\n",
    "    return str(pat).find(\"IRMAS_Validation_Data\") != -1\n",
    "    \n",
    "def is_IRMAS_test(pat: Path):\n",
    "    return str(pat).find(\"IRMAS_Test_Data\") != -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ced942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IRMAS_train_label(pat: Path):\n",
    "    r = re.search(\"\\[[^(\\[\\])]+\\]\", pat.name)\n",
    "    if r:\n",
    "        return [r.group()[1:-1]]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d8a81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IRMAS_valid_label(pat: Path):\n",
    "    with open(os.path.splitext(str(pat))[0] + \".txt\") as file:\n",
    "        return file.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8c14dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(pat: Path):\n",
    "    if is_IRMAS_train(pat):\n",
    "        return get_IRMAS_train_label(pat)\n",
    "    return get_IRMAS_valid_label(pat)\n",
    "\n",
    "def get_single_label(pat: Path):\n",
    "    return get_label(pat)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98b7101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 512  # 1024\n",
    "hop_length = 256  # 512\n",
    "f_min = 20\n",
    "f_max = 8000\n",
    "sample_rate = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adbc0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_song(pat: Path):\n",
    "    return librosa.load(pat, sr=None)[0]\n",
    "class ToSong(Transform):\n",
    "    def encodes(self, song):\n",
    "        if isinstance(song, Path):\n",
    "            return get_song(song)\n",
    "        return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af6fdccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_to_3sr(song):\n",
    "    aplen = sample_rate*3 - len(song)\n",
    "    if aplen < 0: aplen = 0\n",
    "    song = np.concatenate([song, np.zeros(aplen, dtype=\"float32\")])\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17b918ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomClip(Transform):\n",
    "    split_idx=0\n",
    "    def encodes(self, song):\n",
    "        maxran = len(song)-sample_rate*3 + 1\n",
    "        if maxran <= 0: maxran = 1\n",
    "\n",
    "        i = np.random.randint(maxran)\n",
    "        # i=0\n",
    "        song = song[i:i+sample_rate*3]\n",
    "        return extend_to_3sr(song)\n",
    "        \n",
    "class CenterClip(Transform):\n",
    "    split_idx=1\n",
    "    def encodes(self, song):\n",
    "        i = int((len(song) - sample_rate*3) / 2)\n",
    "        song = song[i:i+sample_rate*3]\n",
    "        return extend_to_3sr(song)\n",
    "\n",
    "random_clip = RandomClip().encodes\n",
    "center_clip = CenterClip().encodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d85970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spec(song):\n",
    "    stft = librosa.stft(song, n_fft=n_fft, hop_length=hop_length)\n",
    "    S_db = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
    "    return S_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be1cb325",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToSpec(ItemTransform):\n",
    "    def __init__(self):\n",
    "        self.pipe = Pipeline([get_spec, PILImage.create])\n",
    "    def encodes(self, item):\n",
    "        x = item[0]\n",
    "        return [self.pipe(x)] + item[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "172dcfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8333)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def AccuracyMulti(tresh=0.5):\n",
    "    def acc(x, y):\n",
    "        return 1 - (((x > tresh).float() - y).abs()).float().mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a734ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_song_tfms = [ToSong(), RandomClip(), CenterClip()]\n",
    "get_label_tfms = [get_label, MultiCategorize(), OneHotEncode()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "124c9c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(items, splitter=RandomSplitter()):\n",
    "    splits = splitter(items)\n",
    "    return Datasets(items, [get_song_tfms, get_label_tfms], splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78ff2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = FuncSplitter(lambda x: is_IRMAS_test(x))\n",
    "items = get_song_files(grand_path)\n",
    "train_dset = get_dataset(items, splitter)\n",
    "\n",
    "after_augm = [\n",
    "    ToSpec(),\n",
    "    Resize((256, 156), method=ResizeMethod.Squish),\n",
    "]\n",
    "\n",
    "def get_dataloader(ds, after_augm=after_augm):\n",
    "    after_item = after_augm + [ToTensor(), IntToFloatTensor()]\n",
    "    return ds.dataloaders(bs=64, after_item=after_item, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3c01e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7f5ed53d5c30>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = get_dataloader(train_dset)\n",
    "learn = vision_learner(dls, resnet18, pretrained=True, metrics=AccuracyMulti(tresh=0.8))\n",
    "learn.load('MLBLCLA_model');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01d1aca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [0.30292537808418274,0.8910554051399231]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86182fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sl_windows(song, step=sample_rate):\n",
    "    ran = range(0, len(song)-sample_rate-step, step)\n",
    "    if len(ran) == 0: yield extend_to_3sr([0])\n",
    "    for i in ran: \n",
    "        yield extend_to_3sr(song[i:i+sample_rate*3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84e1ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(learn, song, step=sample_rate, tresh=0.8, perc=0.25):\n",
    "    instr = np.zeros(len(learn.dls.vocab))\n",
    "    for n, sl in enumerate(get_sl_windows(song)):\n",
    "        with io.capture_output() as captured:\n",
    "            instr[learn.predict(sl)[1] > tresh] += 1\n",
    "    return learn.dls.vocab[instr > (n+1)*perc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e68e7190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) ['gel']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(learn, get_song(items[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f996b387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
